{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pngs -> dali dataloader #\n",
    "################################\n",
    "\n",
    "wsi_seq = '20230815_142150'\n",
    "\n",
    "base_dir = \"/mnt/bigdata/placenta/\"\n",
    "\n",
    "import dali\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from nvidia.dali.plugin.pytorch import LastBatchPolicy\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator\n",
    "\n",
    "base_dir = Path(base_dir)\n",
    "tile_dir = base_dir / Path(\"tiles/\" + wsi_seq +\"/\")\n",
    "\n",
    "batch_size = 64 # need to find max that fits into the memory\n",
    "\n",
    "infer_iter = dali.TileInferIterator(tile_dir, batch_size)\n",
    "\n",
    "pipeline = dali.pipe(\n",
    "    batch_size=batch_size, \n",
    "    num_threads=16,\n",
    "    external_data = infer_iter)\n",
    "\n",
    "pii = DALIClassificationIterator(pipeline, last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model #\n",
    "##############\n",
    "\n",
    "model_checkpoint_file = \"/mnt/bigdata/placenta/training_checkpoints/vague-smilodon15.ckpt\"\n",
    "\n",
    "from nvidia_resnets.resnet import (\n",
    "    se_resnext101_32x4d,\n",
    ")\n",
    "\n",
    "model = se_resnext101_32x4d(\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint = torch.load(model_checkpoint_file)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wsi #\n",
    "############\n",
    "\n",
    "tile_size = 500\n",
    "wsi_file = \"/mnt/bigdata/placenta/wsi/\" + wsi_seq + \".tiff\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from pathml.utils import plot_mask\n",
    "from pathml.core import HESlide, Tile, types\n",
    "\n",
    "\n",
    "pml_wsi = HESlide(\n",
    "        wsi_file,\n",
    "        backend=\"openslide\",\n",
    "        slide_type=types.HE,\n",
    "    )\n",
    "\n",
    "print(\"some details of \", pml_wsi.name)\n",
    "print(\"shape: \", pml_wsi.shape)\n",
    "print(\"level_count: \", pml_wsi.slide.level_count)\n",
    "print(\"level_downsamples (from 0 index to n): \", pml_wsi.slide.slide.level_downsamples)\n",
    "print(\"level_dimensions (h,w): \", pml_wsi.slide.slide.level_dimensions)\n",
    "try:\n",
    "    print(\"color profile: \", pml_wsi.slide.slide.color_profile.profile.profile_description)\n",
    "except:\n",
    "    print(\"no color profile information found\")\n",
    "print(\"rgb?: \", pml_wsi.slide_type.rgb)\n",
    "print(\"masks: \", len(pml_wsi.masks))\n",
    "print(\"tiles: \", len(pml_wsi.tiles))\n",
    "print(\"labels: \", pml_wsi.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tensorboard writer #\n",
    "###########################\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# tensorboard --logdir /mnt/bigdata/placenta/tensorboard_data\n",
    "# firefox http://localhost:6006/\n",
    "\n",
    "infer_session = f\"infer-{pml_wsi.name.split('.')[-2]}-{model_checkpoint_file.split('/')[-1].split('.')[-2]}\"\n",
    "\n",
    "tensorboard_log_dir = base_dir / \"tensorboard_data\" / infer_session\n",
    "\n",
    "writer = SummaryWriter(log_dir=tensorboard_log_dir, comment=infer_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference #\n",
    "# function to get tile keys and predictions for each slide #\n",
    "############################################################\n",
    "\n",
    "def infer(dataloader, model, slide_dim: tuple, tile_size = 500) -> dict():\n",
    "    \"\"\" running model evaluation to get tile predictions and keys to later\n",
    "        rebuild the slide and assign tile prediction values for each slide\n",
    "        resulting in a heatmap\n",
    "\n",
    "    Args:\n",
    "        dataloader (torch.utils.data.dataloader.DataLoader, model): pytorch dataloader and trained model\n",
    "\n",
    "    Returns:\n",
    "        dict: keys = wsi filename, values = array of size the number of tiles in wsi, values are prediction values per tile  \n",
    "    \"\"\"\n",
    "    device                          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using {device}\")\n",
    "    if torch.backends.cudnn.enabled == False:\n",
    "        print(\"WARNING: torch.backends.cudnn not enabled!\")\n",
    "    torch.backends.cudnn.benchmark  = True\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # heatmask array has 1 pixel per tile\n",
    "    slide_dim_mini          = (slide_dim[0]//tile_size, slide_dim[1]//tile_size)\n",
    "    heatmask                = np.zeros(slide_dim_mini, dtype=np.float32)\n",
    "    # positive predictions: the higher a value, the more certain the model about the tile featuring signs of an endpoint \n",
    "    pos_predictions         = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0]['data'], data[0]['label']\n",
    "            batch_size = len(images)\n",
    "            images = images.to(device).to(torch.float32)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            pos_predictions_batch = probabilities[:, 1].cpu().numpy() # storing the probability per tile of having an endpoint\n",
    "            pos_predictions.extend(pos_predictions_batch)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                tilex, tiley = int(labels[i][0]), int(labels[i][1])\n",
    "                heatmask[tilex//tile_size, tiley//tile_size] = pos_predictions_batch[i]  \n",
    "    assert batch_size > 0, \"Empty folder you moron\"\n",
    "    \n",
    "    return pos_predictions, heatmask\n",
    "\n",
    "predictions_per_tile, heatmask = infer(pii, model, slide_dim=pml_wsi.shape, tile_size = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_threshold = 0.4\n",
    "# how many tiles predicted to have an endpoint if we consider an endpoint as greater than pos_threshold probability\n",
    "positiles = 0\n",
    "for n in predictions_per_tile:\n",
    "    if n > pos_threshold:\n",
    "        positiles = positiles + 1\n",
    "print(f\"with a treshold of {pos_threshold}, {positiles} tiles of total {len(predictions_per_tile)} ({int(positiles / len(predictions_per_tile) * 100)}%) found to have an endpoint\")\n",
    "\n",
    "print(\"predictions: the higher a value, the more certain the model about the tile featuring signs of an endpoint \")\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(predictions_per_tile, bins=20, edgecolor='black')\n",
    "ax.set_xlabel('positive prediction values')\n",
    "ax.set_ylabel('number of tiles')\n",
    "ax.set_title('tile predictions to have an endpoint')\n",
    "plt.show()\n",
    "writer.add_histogram(f\"tile predictions for {pml_wsi.name.split('.')[-2]}\", np.array(predictions_per_tile), global_step=None, bins=20, walltime=None, max_bins=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 'roc' curve #\n",
    "#######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"The chart helps finding the prediction value threshold for positive tiles i.e. over what value should we consider a tile to reflect an endpoint.\")\n",
    "# create a range of thresholds\n",
    "thresholds = np.linspace(1, 0.5, num=20)  # 50 thresholds from 0 to 1\n",
    "\n",
    "positiles_per_threshold = []\n",
    "# calculate positive tiles for each threshold\n",
    "for threshold in thresholds:\n",
    "    pt = 0\n",
    "    for p in predictions_per_tile:\n",
    "        if p > threshold:\n",
    "            pt = pt + 1\n",
    "    positiles_per_threshold.append(pt)\n",
    "\n",
    "# positiles_per_threshold = [sum(p > threshold for p in pos_predictions) for threshold in thresholds]\n",
    "\n",
    "# normalize threshold values for color mapping\n",
    "norm = plt.Normalize(vmin=min(thresholds), vmax=max(thresholds))\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# plot each segment with color mapping to the thresholds\n",
    "for i in range(len(thresholds) - 1):\n",
    "    color = cmap(norm(thresholds[i]))\n",
    "    ax.plot(positiles_per_threshold[i:i+2], thresholds[i:i+2], color=color, lw=2)\n",
    "\n",
    "# colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Important to ensure the colorbar works with our custom colors\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Threshold')\n",
    "\n",
    "ax.set_xlabel('Number of Positive Tiles')\n",
    "ax.set_ylabel('Threshold')\n",
    "ax.set_title('Positive Tiles vs Threshold')\n",
    "\n",
    "# mirror chart horizontally by reversing the x-axis\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure('Positive Tile vs Threshold', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display heatmask on wsi #\n",
    "###########################\n",
    "import numpy.ma as ma\n",
    "\n",
    "try:\n",
    "    resolution_level = 4   # 0 is the highest resolution, need to use the index of level_downsamples\n",
    "    # dimensions are transposed!!! needed to invert.. (pml_wsi.slide.slide.level_dimensions[0][1], pml_wsi.slide.slide.level_dimensions[0][0]))\n",
    "    region = pml_wsi.slide.extract_region(\n",
    "        location=(0, 0),\n",
    "        size=(pml_wsi.slide.slide.level_dimensions[resolution_level][1], pml_wsi.slide.slide.level_dimensions[resolution_level][0]),\n",
    "        level=resolution_level\n",
    "        )\n",
    "    print(\"Working with pyramid resolution level\", resolution_level, \"shape:\", region.shape[0:1])\n",
    "except Exception as e:\n",
    "    print(\"Resolution level not found, using original size. Error: \", e)\n",
    "    # dimensions are transposed!!! needed to invert.. (pml_wsi.slide.slide.level_dimensions[0][1], pml_wsi.slide.slide.level_dimensions[0][0]))\n",
    "    region = pml_wsi.slide.extract_region(\n",
    "        location=(0, 0),\n",
    "        size=(pml_wsi.slide.slide.level_dimensions[0][1], pml_wsi.slide.slide.level_dimensions[0][0])\n",
    "        )\n",
    "\n",
    "def customTile():\n",
    "    return Tile(region, coords=(0, 0), name=\"testregion\", slide_type=types.HE)\n",
    "\n",
    "tile = customTile()\n",
    "\n",
    "# display original image only\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "wsi_height, wsi_width = pml_wsi.shape\n",
    "extent = [0, wsi_width, wsi_height, 0]\n",
    "plt.imshow(region, extent=extent)\n",
    "plt.colorbar()\n",
    "plt.title(f'wsi {pml_wsi.name}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure('Original WSI', fig)\n",
    "\n",
    "# display heatmask with all values\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "wsi_height, wsi_width = pml_wsi.shape\n",
    "extent = [0, wsi_width, wsi_height, 0]\n",
    "plt.imshow(heatmask, cmap='Greys', alpha=1, extent=extent, interpolation='hamming')\n",
    "plt.colorbar()\n",
    "plt.title('heatmask only with full scale prediction values')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure('Full spectrum heatmask', fig)\n",
    "\n",
    "# display heatmask with threshold\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "wsi_height, wsi_width = pml_wsi.shape\n",
    "extent = [0, wsi_width, wsi_height, 0]\n",
    "thresholded_heatmask = ma.masked_outside(heatmask, pos_threshold, 1)\n",
    "plt.imshow(thresholded_heatmask, cmap='YlGnBu', alpha=1, extent=extent, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(f'heatmask only above threshold of {pos_threshold}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure(f'Heatmask only in range between {pos_threshold} and 1', fig)\n",
    "\n",
    "# display heatmask drawn on wsi\n",
    "plt.figure(figsize=(20, 8))\n",
    "wsi_height, wsi_width = pml_wsi.shape\n",
    "# extent = [0, wsi_width, wsi_height, 0] ??? also works \n",
    "extent = [0, wsi_width, wsi_height, 0]\n",
    "plt.imshow(region, extent=extent)\n",
    "plt.imshow(heatmask, cmap='Greys', alpha=0.5, extent=extent, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('heatmask overlay on wsi')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure(f'Full spectrum heatmask overlay on wsi', fig)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and play some music as well\n",
    "import subprocess\n",
    "mp3_file_path = '/home/peet/Downloads/clean-trap-loop-131bpm-136738.mp3'\n",
    "subprocess.run(['mpg123', mp3_file_path])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
